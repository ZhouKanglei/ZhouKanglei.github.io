
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"About Me I am a final-year PhD candidate at the State Key Lab of VR Technology and Systems, SCSE, Beihang University. I am expected to graduate in June 2025. My research primarily focuses on utilizing structured human knowledge to enhance human motion analysis.\n Announcement: I am seeking potential research job opportunities and would be delighted to discuss how my expertise can contribute to your team.\n Call Me Connie Interestingly, during my ECCV 2024 Oral \u0026#34;oral presentation at ECCV 2024 the automatic translation system rendered Kanglei as Connie. Since the pronunciation is also quite similar, I decided to keep Connie as my English name.\n Degree Institution Year   PhD Candidate in CS Beihang University Supervised by Prof. Xiaohui Liang 2020–Now   Visiting Student Durham University Supervised by Prof. Hubert P. H. Shum                          and Dr. Frederick W. B. Li 2024   BSc in CS Henan Normal University 2016–2020   Exchange Student Frankfurt University of Applied Science 2019   -- ","date":1748313480,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1748313480,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"About Me I am a final-year PhD candidate at the State Key Lab of VR Technology and Systems, SCSE, Beihang University. I am expected to graduate in June 2025. My research primarily focuses on utilizing structured human knowledge to enhance human motion analysis.","tags":null,"title":"Kanglei Zhou","type":"authors"},{"authors":null,"categories":null,"content":"Biography PhD, 2024 - Present, Durham University, UK\nResearch Interests  Action quality assessment   Attention: See his profile to view our co-authored publications.\n ","date":1755648000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1755648000,"objectID":"94af7104f034c923c70eb9459a381c73","permalink":"https://zhoukanglei.github.io/people/ruisheng-han/","publishdate":"2025-08-20T00:00:00Z","relpermalink":"/people/ruisheng-han/","section":"people","summary":"Postgraduate Student @ Durham University","tags":["People","Co-supervised Students"],"title":"Ruisheng Han","type":"people"},{"authors":null,"categories":null,"content":"He is my PhD supervisor at Beihang University.\n","date":1754006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754006400,"objectID":"d40a87a226b9d522803c052d61f974e2","permalink":"https://zhoukanglei.github.io/people/xiaohui-liang/","publishdate":"2025-08-01T00:00:00Z","relpermalink":"/people/xiaohui-liang/","section":"people","summary":"Professor @ BUAA","tags":["Supervisor","People"],"title":"Xiaohui Liang","type":"people"},{"authors":null,"categories":null,"content":"","date":1754006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754006400,"objectID":"8e37ebbfedb9c88a50dcd65de0efd569","permalink":"https://zhoukanglei.github.io/people/hubert/","publishdate":"2025-08-01T00:00:00Z","relpermalink":"/people/hubert/","section":"people","summary":"Professor @ Durham University","tags":["Collaborators","People"],"title":"Hubert P. H. Shum","type":"people"},{"authors":null,"categories":null,"content":"","date":1754006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754006400,"objectID":"9b17dddec3c925dd43cfc9aa47e77d67","permalink":"https://zhoukanglei.github.io/people/liyuan-wang/","publishdate":"2025-08-01T00:00:00Z","relpermalink":"/people/liyuan-wang/","section":"people","summary":"Assistant Professor @ THU","tags":["Collaborators","People"],"title":"Liyuan Wang","type":"people"},{"authors":null,"categories":null,"content":"Biography He is my co-supervised master’s student (2023-2026) at Beihang University, working under Prof. Xiaohui Liang.\nResearch Interests  Hand pose estimation  ","date":1754006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754006400,"objectID":"fc5e4226f823c3a36d7b1a5c8f3fd57d","permalink":"https://zhoukanglei.github.io/people/zikai-hao/","publishdate":"2025-08-01T00:00:00Z","relpermalink":"/people/zikai-hao/","section":"people","summary":"Postgraduate Student @ BUAA","tags":["People","Co-supervised Students"],"title":"Zikai Hao","type":"people"},{"authors":["Kanglei Zhou","Hubert P. H. Shum","Frederick W. B. Li","Xingxing Zhang","Xiaohui Liang"],"categories":[],"content":"Core Idea 💡 A follow-up to our IJCAI 2024 paper, proposing a domain shift and feature adaptation outperforms task reconstruction methods.\n","date":1748313480,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748313480,"objectID":"449afdc1efeb9759c3fbeed5387bf345","permalink":"https://zhoukanglei.github.io/publications/phi_aqa/","publishdate":"2025-06-04T21:10:00+08:00","relpermalink":"/publications/phi_aqa/","section":"publications","summary":"Long-term Action Quality Assessment (AQA) aims to evaluate the quantitative performance of actions in long videos. However, existing methods face challenges due to domain shifts between the pre-trained large-scale action recognition backbones and the specific AQA task, thereby hindering their performance. This arises since fine-tuning resource-intensive backbones on small AQA datasets is impractical. We address this by identifying two levels of domain shift: task-level, regarding differences in task objectives, and feature-level, regarding differences in important features. For feature-level shifts, which are more detrimental, we propose Progressive Hierarchical Instruction (PHI) with two strategies. First, Gap Minimization Flow (GMF) leverages flow matching to progressively learn a fast flow path that reduces the domain gap between initial and desired features across shallow to deep layers. Additionally, a temporally-enhanced attention module captures long-range dependencies essential for AQA. Second, List-wise Contrastive Regularization (LCR) facilitates coarse-to-fine alignment by comprehensively comparing batch pairs to learn fine-grained cues while mitigating domain shift. Integrating these modules, PHI offers an effective solution. Experiments demonstrate that PHI achieves state-of-the-art performance on three representative long-term AQA datasets, proving its superiority in addressing the domain shift for long-term AQA.","tags":["Representative Work","Action Quality Assessment","CCF A","Domain Shift"],"title":"PHI: Bridging Domain Shift in Long-Term Action Quality Assessment via Progressive Hierarchical Instruction","type":"publications"},{"authors":null,"categories":null,"content":"🎉 I am beyond excited to share that I have successfully defended my PhD thesis! This achievement represents years of dedication, research, and perseverance. A heartfelt thank you to everyone who supported and encouraged me throughout this journey. Stay tuned for updates on the exciting paths ahead!\n","date":1747612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747612800,"objectID":"5f26703b55dfa58de72b073e496927a9","permalink":"https://zhoukanglei.github.io/news/20250519-phd_defence/","publishdate":"2025-05-23T00:00:00Z","relpermalink":"/news/20250519-phd_defence/","section":"news","summary":"Successfully defended my PhD thesis","tags":["Personal"],"title":"A Milestone Achieved","type":"news"},{"authors":null,"categories":null,"content":"With the recent update to the Wochemy theme, I have upgraded my website. This new version is built on the foundation of simongravelle.github.io.\n","date":1745107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1745107200,"objectID":"4e63f1b1303b52218616011439f2cd0d","permalink":"https://zhoukanglei.github.io/news/20250420-new_website/","publishdate":"2025-04-20T00:00:00Z","relpermalink":"/news/20250420-new_website/","section":"news","summary":"Discover the upgraded website","tags":["Personal"],"title":"New Website Launch","type":"news"},{"authors":["Yue Ma","Kanglei Zhou","Fuyang Yu","Frederick W. B. Li","Xiaohui Liang"],"categories":[],"content":"","date":1738034602,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738034602,"objectID":"c36a39992511eda0021816027a505aac","permalink":"https://zhoukanglei.github.io/publications/probhmi/","publishdate":"2025-01-28T11:23:22+08:00","relpermalink":"/publications/probhmi/","section":"publications","summary":"","tags":["CCF B"],"title":"Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks","type":"publications"},{"authors":["Kanglei Zhou","Zikai Hao","Liyuan Wang","Xiaohui Liang"],"categories":[],"content":"","date":1737973698,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1737973698,"objectID":"394bc54e8a10a2436e37b50b95d184a5","permalink":"https://zhoukanglei.github.io/publications/cvqa/","publishdate":"2025-01-27T18:28:18+08:00","relpermalink":"/publications/cvqa/","section":"publications","summary":"Virtual Reality Video Quality Assessment (VR-VQA) aims to evaluate the perceptual quality of 360-degree videos, which is crucial for ensuring a distortion-free user experience. Traditional VR-VQA methods trained on static datasets with limited distortion diversity struggle to balance correlation and precision. This becomes particularly critical when generalizing to diverse VR content and continually adapting to dynamic and evolving video distribution variations. To address these challenges, we propose a novel approach for assessing the perceptual quality of VR videos, Adaptive Score Alignment Learning (ASAL). ASAL integrates correlation loss with error loss to enhance alignment with human subjective ratings and precision in predicting perceptual quality. In particular, ASAL can naturally adapt to continually changing distributions through a feature space smoothing process that enhances generalization to unseen content. To further improve continual adaptation to dynamic VR environments, we extend ASAL with adaptive memory replay as a novel Continual Learning (CL) framework. Unlike traditional CL models, ASAL utilizes key frame extraction and feature adaptation to address the unique challenges of non-stationary variations with both the computation and storage restrictions of VR devices. We establish a comprehensive benchmark for VR-VQA and its CL counterpart, introducing new data splits and evaluation metrics. Our experiments demonstrate that ASAL outperforms recent strong baseline models, achieving overall correlation gains of up to 4.78% in the static joint training setting and 12.19% in the dynamic CL setting on various datasets. This validates the effectiveness of ASAL in addressing the inherent challenges of VR-VQA. Our code is available at https://github.com/ZhouKanglei/ASAL_CVQA.","tags":["Representative Work","CCF A","Continual Learning"],"title":"Adaptive Score Alignment Learning for Continual Perceptual Quality Assessment of 360-Degree Videos in Virtual Reality","type":"publications"},{"authors":null,"categories":null,"content":"Research Statement of My Previous Work My research addresses critical challenges in human motion analysis, particularly in aerospace and medical rehabilitation. It focuses on three interconnected scientific problems: motion perception anomalies caused by physiological or pathological factors, negative transfer due to limited samples, and catastrophic forgetting resulting from non-stationary data distributions. Leveraging spatiotemporal graph models, domain adaptation, and continual learning frameworks, I have developed innovative methods that have achieved significant academic and practical outcomes. These methods have been validated in two key applications: microgravity grasping training for aerospace and motion assessment for juvenile dermatomyositis in medical rehabilitation, demonstrating substantial value for national defense and healthcare.\nTo address these challenges, I proposed three methods: a robust denoising method for human motion perception to mitigate perception anomalies, a domain adaptation method for human motion assessment to overcome negative transfer, and a continual learning method for human motion assessment to address catastrophic forgetting. These methods are interdependent: the first provides high-quality data for the latter two, while the third builds upon the second to meet practical application requirements. Together, they represent a significant advancement in the field of human motion analysis.\nRobust Denoising Method for Human Motion Perception In virtual reality interactions, hand tremors caused by user fatigue severely degrade data quality and impair the interaction experience. Similarly, pathological tremors, such as those in Parkinson’s disease, pose challenges for precise interaction. To address this, I proposed a spatiotemporal graph autoencoder for hand motion denoising [1]. However, denoising alone may lead to over-smoothing of motion, which can hinder the accurate interpretation of user intent. To address this limitation, I introduced a prediction task that forecasts future motion [2]. This approach retains dynamic information in the feature space, significantly mitigating over-smoothing and enhancing both data collection efficiency and accuracy.\nThese methods were integrated into a prototype system for simulated microgravity grasping training in aerospace [3], providing an immersive and cost-effective ground-based training method for astronauts while also serving educational purposes. Users of the proposed system achieved 50% and 59% reductions in training time and repetitions, respectively, compared to the state-of-the-art CLAP system.\nDomain Adaptation Method for Human Motion Assessment Motion quality assessment aims to evaluate the quality of motion execution using machine learning, with applications in sports analysis, medical rehabilitation, and skill assessment. However, in practice, data scarcity leads to small sample sizes, causing models to overfit, while existing domain adaptation methods suffer from negative transfer. To address this, innovative graph network-based methods were proposed [4], [5], [6], significantly improving the robustness and interpretability of motion assessment.\nThese methods were integrated into a juvenile dermatomyositis motion assessment system. In experiments at the Capital Institute of Pediatrics, the system improved diagnostic accuracy by 4.99% and efficiency by 20%.\nContinual Learning Method for Human Motion Assessment In practical applications, individual differences and data distributions change over time, while protecting user privacy, especially for patients, is crucial. To address this, I proposed the task of continual action quality assessment for the first time, along with strategies to tackle the dual challenges of privacy protection and catastrophic forgetting [7], [8].\nThis work was presented as oral talks at VR 2025 and ECCV 2024. Notably, the oral acceptance rate for ECCV 2024 was only 2.3%, with reviewers highlighting its “practical significance” and giving it a “strong accept” rating during the initial review. The VR 2025 paper was recommended for publication in the IEEE TVCG, a top-tier journal in virtual reality.\nReferences   Kanglei Zhou et al. “STGAE: Spatial-Temporal Graph Auto-Encoder for Hand Motion Denoising.” IEEE ISMAR, 2021. (Top AR Conference, Core A*)\n  Kanglei Zhou et al. “Multi-Task Spatial-Temporal Graph Auto-Encoder for Hand Motion Denoising.” IEEE Transactions on Visualization and Computer Graphics (TVCG), 2024. (Top VR Journal, CCF A)\n  Kanglei Zhou et al. “A Mixed Reality Training System for Hand-Object Interaction in Simulated Microgravity Environments.” IEEE ISMAR, 2023. (Top AR Conference, Core A*)\n  Kanglei Zhou et al. “A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile Dermatomyositis.” IEEE TVCG, 2023. (Top VR Journal, CCF A, Recommended by VR 2023, Acceptance Rate: 10%)\n  Kanglei Zhou et al. “CoFInAl: Enhancing Action Quality Assessment with …","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"5dba78648dd0053d9a7bceb28321462d","permalink":"https://zhoukanglei.github.io/gallery/methods/","publishdate":"2025-04-20T00:00:00Z","relpermalink":"/gallery/methods/","section":"gallery","summary":"This research tackles three key challenges in human motion analysis - **motion perception anomalies**, **negative transfer due to limited samples**, and **catastrophic forgetting in non-stationary data distributions**. By leveraging spatiotemporal graph models, domain adaptation, and continual learning, innovative methods were developed to address these issues, achieving significant advancements in aerospace training and medical rehabilitation applications.","tags":null,"title":"My Previous Work","type":"gallery"},{"authors":null,"categories":null,"content":"Research Proposal on Multi-Modal Action Quality Assessment  If you are interested in this proposal, please feel free to contact me.\n Challenges within Existing Multi-Modal Action Quality Assessment Methods Despite the potential benefits of multi-modal Action Quality Assessment (see our survey for details), several challenges remain to be addressed to ensure accurate and interpretable assessment.\n Modality Heterogeneity and Missing Data: Integrating diverse data sources is challenging due to differing feature representations. Additionally, missing modalities caused by sensor failures or acquisition issues can significantly degrade performance. Lack of Interpretability: Many current models function as black boxes, making it difficult to understand their decision-making processes. This lack of transparency is particularly concerning in high-stakes applications like muscle strength assessment, where predictions must be explainable and trustworthy.  Addressing these challenges requires the development of innovative methods to effectively integrate heterogeneous data, handle missing modalities, and provide interpretable predictions.\n","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"a37febdeaa161a8ccf72f5cd7d0d5ec6","permalink":"https://zhoukanglei.github.io/gallery/proposal/","publishdate":"2025-04-20T00:00:00Z","relpermalink":"/gallery/proposal/","section":"gallery","summary":"This proposal explores innovative solutions for Multi-Modal Action Quality Assessment, focusing on addressing challenges such as modality heterogeneity, missing data, and lack of interpretability in current methods.","tags":null,"title":"Research Proposal","type":"gallery"},{"authors":["Kanglei Zhou","Ruizhi Cai","Liyuan Wang","Hubert P. H. Shum","Xiaohui Liang"],"categories":[],"content":"","date":1734258401,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734258401,"objectID":"07a5b6d7b0e27daad92267be0edcc806","permalink":"https://zhoukanglei.github.io/publications/aqa_survey/","publishdate":"2024-12-15T18:26:41+08:00","relpermalink":"/publications/aqa_survey/","section":"publications","summary":"","tags":["Survey"],"title":"A Comprehensive Survey of Action Quality Assessment: Method and Benchmark","type":"publications"},{"authors":["Kanglei Zhou","Liyuan Wang","Xingxing Zhang","Hubert P. H. Shum","Frederick W. B. Li","Jianguo Li","Xiaohui Liang"],"categories":[],"content":"","date":1719842027,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719842027,"objectID":"8f454bdd99f98a0767ce4b7cd50570ca","permalink":"https://zhoukanglei.github.io/publications/magr_aqa/","publishdate":"2024-07-01T19:43:47+08:00","relpermalink":"/publications/magr_aqa/","section":"publications","summary":"Action Quality Assessment (AQA) evaluates diverse skills but models struggle with non-stationary data. We propose Continual AQA (CAQA) to refine models using sparse new data. Feature replay preserves memory without storing raw inputs. However, the misalignment between static old features and the dynamically changing feature manifold causes severe catastrophic forgetting. To address this novel problem, we propose Manifold-Aligned Graph Regularization (MAGR), which first aligns deviated old features to the current feature manifold, ensuring representation consistency. It then constructs a graph jointly arranging old and new features aligned with quality scores. Experiments show MAGR outperforms recent strong baselines with up to 6.56%, 5.66%, 15.64%, and 9.05% correlation gains on the MTL-AQA, FineDiving, UNLV-Dive, and JDM-MSA split datasets, respectively. This validates MAGR for continual assessment challenges arising from non-stationary skill variations.","tags":["Representative Work","Action Quality Assessment","Continual Learning","CCF B","CAAI/THU A"],"title":"MAGR: Manifold-Aligned Graph Regularization for Continual Action Quality Assessment","type":"publications"},{"authors":["Kanglei Zhou","Junlin Li","Ruizhi Cai","Liyuan Wang","Xinxing Zhang","Xiaohui Liang"],"categories":[],"content":"","date":1713473353,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713473353,"objectID":"1e9b2f46047249f889332657db1c1b23","permalink":"https://zhoukanglei.github.io/publications/cofinal_aqa/","publishdate":"2024-04-18T21:49:13+01:00","relpermalink":"/publications/cofinal_aqa/","section":"publications","summary":"Action Quality Assessment (AQA) is pivotal for quantifying actions across domains like sports and medical care. Existing methods often rely on pre-trained backbones from large-scale action recognition datasets to boost performance on smaller AQA datasets. However, this common strategy yields suboptimal results due to the inherent struggle of these backbones to capture the subtle cues essential for AQA. Moreover, fine-tuning on smaller datasets risks overfitting. To address these issues, we propose Coarse-to-Fine Instruction Alignment (CoFInAl). Inspired by recent advances in large language model tuning, CoFInAl aligns AQA with broader pre-trained tasks by reformulating it as a coarse-to-fine classification task. Initially, it learns grade prototypes for coarse assessment and then utilizes fixed sub-grade prototypes for fine-grained assessment. This hierarchical approach mirrors the judging process, enhancing interpretability within the AQA framework. Experimental results on two long-term AQA datasets demonstrate CoFInAl achieves state-of-the-art performance with significant correlation gains of 5.49% and 3.55% on Rhythmic Gymnastics and Fis-V, respectively. Our Code is available at https://github.com/ZhouKanglei/CoFInAl_AQA.","tags":["Representative Work","Action Quality Assessment","CCF A","Domain Shift"],"title":"CoFInAl: Enhancing Action Quality Assessment with Coarse-to-Fine Instruction Alignment","type":"publications"},{"authors":["Kanglei Zhou","Hubert P. H. Shum","Frederick W. B. Li","Xiaohui Liang"],"categories":[],"content":"","date":1701172703,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701172703,"objectID":"3fbc969be2bbb0376243df9d0b500b3e","permalink":"https://zhoukanglei.github.io/publications/multi-stgae/","publishdate":"2023-11-28T19:58:23+08:00","relpermalink":"/publications/multi-stgae/","section":"publications","summary":"","tags":["Representative Work","Hand Motion","CCF A"],"title":"Multi-Task Spatial-Temporal Graph Auto-Encoder for Hand Motion Denoising","type":"publications"},{"authors":["Juntao Li","Hongmei Zhang","Bingyu Mu","Hongliang Zuo","Kanglei Zhou"],"categories":[],"content":"","date":1701172251,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701172251,"objectID":"9fbfd956ff38f2dcdc99fb144fe0548a","permalink":"https://zhoukanglei.github.io/publications/lp_sgl/","publishdate":"2023-05-28T19:50:51+08:00","relpermalink":"/publications/lp_sgl/","section":"publications","summary":" Single-cell RNA sequencing (scRNA-seq) enables the resolution of cellular heterogeneity in diseases and facilitates the identification of novel cell types and subtypes. However, the grouping effects caused by cell–cell interactions are often overlooked in the development of tools for identifying subpopulations. We proposed LP_SGL which incorporates cell group structure to identify phenotype-associated subpopulations by integrating scRNA-seq, bulk expression and bulk phenotype data. Cell groups from scRNA-seq data were obtained by the Leiden algorithm, which facilitates the identification of subpopulations and improves model robustness. LP_SGL identified a higher percentage of cancer cells, T cells and tumor-associated cells than Scissor and scAB on lung adenocarcinoma diagnosis, melanoma drug response and liver cancer survival datasets, respectively. Biological analysis on three original datasets and four independent external validation sets demonstrated that the signaling genes of this cell subset can predict cancer, immunotherapy and survival. ","tags":[],"title":"Identifying phenotype-associated subpopulations through LP_SGL","type":"publications"},{"authors":["Kanglei Zhou","Chen Chen","Yue Ma","Zhiying Leng","Hubert P. H. Shum","Frederick W. B. Li","Xiaohui Liang"],"categories":[],"content":"","date":1699729200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699729200,"objectID":"775c79da0a7850b7d3fbdfda98d6686b","permalink":"https://zhoukanglei.github.io/publications/mr_hoi/","publishdate":"2023-10-06T00:00:00Z","relpermalink":"/publications/mr_hoi/","section":"publications","summary":" As human exploration of space continues to progress, the use of Mixed Reality (MR) for simulating microgravity environments and facilitating training in hand-object interaction holds immense practical significance. However, hand-object interaction in microgravity presents distinct challenges compared to terrestrial environments due to the absence of gravity. This results in heightened agility and inherent unpredictability of movements that traditional methods struggle to simulate accurately. To this end, we propose a novel MR-based hand-object interaction system in simulated microgravity environments, leveraging physics-based simulations to enhance the interaction between the user’s real hand and virtual objects. Specifically, we introduce a physics-based hand-object interaction model that combines impulse-based simulation with penetration contact dynamics. This accurately captures the intricacies of hand-object interaction in microgravity. By considering forces and impulses during contact, our model ensures realistic collision responses and enables effective object manipulation in the absence of gravity. The proposed system presents a cost-effective solution for users to simulate object manipulation in microgravity. It also holds promise for training space travelers, equipping them with greater immersion to better adapt to space missions. The system reliability and fidelity test verifies the superior effectiveness of our system compared to the state-of-the-art CLAP system. ","tags":["Core A*","Hand Motion"],"title":"A Mixed Reality Training System for Hand-Object Interaction in Simulated Microgravity Environments","type":"publications"},{"authors":["Kanglei Zhou","Yue Ma","Hubert P. H. Shum","Xiaohui Liang"],"categories":[],"content":"","date":1685619827,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685619827,"objectID":"710079dd9ef62200449bb5151594aa09","permalink":"https://zhoukanglei.github.io/publications/hgcn_aqa/","publishdate":"2023-06-01T19:43:47+08:00","relpermalink":"/publications/hgcn_aqa/","section":"publications","summary":"Action quality assessment (AQA) automatically evaluates how well humans perform actions in a given video, a technique widely used in fields such as rehabilitation medicine, athletic competitions, and specific skills assessment. However, existing works that uniformly divide the video sequence into small clips of equal length suffer from intra-clip confusion and inter-clip incoherence, hindering the further development of AQA. To address this issue, we propose a hierarchical graph convolutional network (GCN). First, semantic information confusion is corrected through clip refinement, generating the 'shot' as the basic action unit. We then construct a scene graph by combining several consecutive shots into meaningful scenes to capture local dynamics. These scenes can be viewed as different procedures of a given action, providing valuable assessment cues. The video-level representation is finally extracted via sequential action aggregation among scenes to regress the predicted score distribution, enhancing discriminative features and improving assessment performance. Experiments on the AQA-7, MTLAQA, and JIGSAWS datasets demonstrate the superiority of the proposed hierarchical GCN over state-of-the-art methods.","tags":["Representative Work","Action Quality Assessment","CCF B"],"title":"Hierarchical Graph Convolutional Networks for Action Quality Assessment","type":"publications"},{"authors":["Kanglei Zhou","Ruizhi Cai","Yue Ma","Qingqing Tan","Xinning Wang","Jianguo Li","Hubert P. H. Shum","Frederick W. B. Li","Song Jin","Xiaohui Liang"],"categories":[],"content":"","date":1683791483,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683791483,"objectID":"c345f63ec7b680860d7a7365a9dc8495","permalink":"https://zhoukanglei.github.io/publications/jdm_aqa/","publishdate":"2023-05-11T15:51:23+08:00","relpermalink":"/publications/jdm_aqa/","section":"publications","summary":"As the most common idiopathic inflammatory myopathy in children, juvenile dermatomyositis (JDM) is characterized by skin rashes and muscle weakness. The childhood myositis assessment scale (CMAS) is commonly used to measure the degree of muscle involvement for diagnosis or rehabilitation monitoring. On the one hand, human diagnosis is not scalable and may be subject to personal bias. On the other hand, automatic action quality assessment (AQA) algorithms cannot guarantee 100% accuracy, making them not suitable for biomedical applications. As a solution, we propose a video-based augmented reality system for human-in-the-loop muscle strength assessment of children with JDM. We first propose an AQA algorithm for muscle strength assessment of JDM using contrastive regression trained by a JDM dataset. Our core insight is to visualize the AQA results as a virtual character facilitated by a 3D animation dataset, so that users can compare the real-world patient and the virtual character to understand and verify the AQA results. To allow effective comparisons, we propose a video-based augmented reality system. Given a feed, we adapt computer vision algorithms for scene understanding, evaluate the optimal way of augmenting the virtual character into the scene, and highlight important parts for effective human verification. The experimental results confirm the effectiveness of our AQA algorithm, and the results of the user study demonstrate that humans can more accurately and quickly assess the muscle strength of children using our system.","tags":["Representative Work","Action Quality Assessment","CCF A"],"title":"A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile Dermatomyositis","type":"publications"},{"authors":["Liuyuan Chen","Kanglei Zhou","Junchang Jing","Haiju Fan","Juntao Li"],"categories":[],"content":"","date":1659429454,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659429454,"objectID":"c4ba2f4d2a629b4b07170a537719bee1","permalink":"https://zhoukanglei.github.io/publications/twinmultipath/","publishdate":"2022-08-02T16:37:34+08:00","relpermalink":"/publications/twinmultipath/","section":"publications","summary":"The twin support vector machine and its extensions have made great achievements in dealing with binary classification problems. However, it suffers from difficulties in effective solution of multi-classification and fast model selection. This work devotes to the fast regularization parameter tuning algorithm for the twin multi-class support vector machine. Specifically, a novel sample data set partition strategy is first adopted, which is the basis for the model construction. Then, combining the linear equations and block matrix theory, the Lagrangian multipliers are proved to be piecewise linear w.r.t. the regularization parameters, so that the regularization parameters are continuously updated by only solving the break points. Next, Lagrangian multipliers are proved to be 1 as the regularization parameter approaches infinity, thus, a simple yet effective initialization algorithm is devised. Finally, eight kinds of events are defined to seek for the starting event for the next iteration. Extensive experimental results on nine UCI data sets show that the proposed method can achieve comparable classification performance without solving any quadratic programming problem.","tags":[],"title":"Solution Path Algorithm for Twin Multi-class Support Vector Machine","type":"publications"},{"authors":["Kanglei Zhou","Qiyang Zhang","Juntao Li"],"categories":[],"content":"","date":1654568703,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654568703,"objectID":"540f1de76698eaa4a8bae983e34561ff","permalink":"https://zhoukanglei.github.io/publications/tsvmpath/","publishdate":"2022-07-14T10:25:03+08:00","relpermalink":"/publications/tsvmpath/","section":"publications","summary":"Twin support vector machine (TSVM) has attracted much attention in the field of machine learning with good generalization ability and computational performance.　However, the conventional grid search method is very time-consuming to obtain the optimal regularization parameter. To address this problem, we develop a novel fast regularization parameter tuning algorithm for TSVM, named TSVMPath. After transforming the models of two sub-optimization problems, we divide the two classes of samples into different sets. Lagrangian multipliers are then proved to be piecewise linear concerning the corresponding regularization parameters, greatly extending the search space of the solution. By proving that the Lagrangian multipliers of two sub-optimization models are 1 when the regularization parameters approach infinity, we design a simple yet effective initialization. As a result, the entirely regularized solution path can be obtained without solving quadratic programming problems. Four types of events are finally defined to update the solution path. Experiments on 8 UCI datasets show that both the prediction accuracy of TSVMPath is superior to the best competing methods, with up to four orders of magnitude speed-up for the computational overhead compared with the grid search method.","tags":[],"title":"TSVMPath: Fast Regularization Parameter Tuning Algorithm for Twin Support Vector Machine","type":"publications"},{"authors":["Kanglei Zhou","Zhiyuan Cheng","Hubert PH Shum","Frederick WB Li","Xiaohui Liang"],"categories":[],"content":"","date":1634178309,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634178309,"objectID":"22416f51e1a331d5f14290f3773f12e7","permalink":"https://zhoukanglei.github.io/publications/stgae/","publishdate":"2021-10-14T10:25:09+08:00","relpermalink":"/publications/stgae/","section":"publications","summary":"Hand object interaction in mixed reality (MR) relies on the accurate tracking and estimation of human hands, which provide users with a sense of immersion. However, raw captured hand motion data always contains errors such as joints occlusion, dislocation, high-frequency noise, and involuntary jitter. Denoising and obtaining the hand motion data consistent with the user’s intention are of the utmost importance to enhance the interactive experience in MR. To this end, we propose an end-to-end method for hand motion denoising using the spatial-temporal graph auto-encoder (STGAE). The spatial and temporal patterns are recognized simultaneously by constructing the consecutive hand joint sequence as a spatial-temporal graph. Considering the complexity of the articulated hand structure, a simple yet effective partition strategy is proposed to model the physic-connected and symmetry-connected relationships. Graph convolution is applied to extract structural constraints of the hand, and a self-attention mechanism is to adjust the graph topology dynamically. Combining graph convolution and temporal convolution, a fundamental graph encoder or decoder block is proposed. We finally establish the hourglass residual auto-encoder to learn a manifold projection operation and a corresponding inverse projection through stacking these blocks. In this work, the proposed framework has been successfully used in hand motion data denoising with preserving structural constraints between joints. Extensive quantitative and qualitative experiments show that the proposed method has achieved better performance than the state-of-the-art approaches.","tags":["Core A*"],"title":"STGAE: Spatial-Temporal Graph Auto-Encoder for Hand Motion Denoising","type":"publications"},{"authors":["Kanglei Zhou","Jingjing Fan","Haiju Fan","Ming Li"],"categories":[],"content":"","date":1594694482,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594694482,"objectID":"421136a4bbff4806ddbc89a7d83a7c28","permalink":"https://zhoukanglei.github.io/publications/drpe_cs/","publishdate":"2020-01-14T10:41:22+08:00","relpermalink":"/publications/drpe_cs/","section":"publications","summary":"A secure optical digital image encryption scheme with authentication capability is proposed using double random-phase encoding (DRPE) and compressed sensing (CS). Phase information of the plaintext image is obtained using DRPE and quantized to generate authentication information. Simultaneously, the plaintext image is compressed by CS and its measurements are quantized using the sigmoid map. Then the ciphertext image is obtained by permutation and diffusion after authentication information is embedded in quantified measurements. At receiving end, the authentication information is first extracted by inverse permutation and diffusion, and then the authentication image is obtained by inverse DRPE. Finally, the ciphertext image can be blindly authenticated using a nonlinear cross-correlation method with authentication image and reconstructed image. Experimental results demonstrate the effectiveness of our proposed scheme.","tags":[],"title":"Secure image encryption scheme using double random-phase encoding and compressed sensing","type":"publications"},{"authors":["Kanglei Zhou","Minghui Xu","Jidong Luo","Haiju Fan","Ming Li"],"categories":[],"content":"","date":1571021628,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571021628,"objectID":"21d3ae3315465570fd723f7b24d91b42","permalink":"https://zhoukanglei.github.io/publications/cryptanalysis_mhm/","publishdate":"2019-10-14T10:53:48+08:00","relpermalink":"/publications/cryptanalysis_mhm/","section":"publications","summary":"Recently, a novel image encryption scheme has been proposed based on a modified Henon map using hybrid chaotic shift transform. This paper analyzes the security of the original encryption scheme and finds it insecure against the chosen-plaintext attack. Meanwhile, an efficient strategy is proposed to break the original encryption scheme with several chosen-plaintext attacks. The experimental results show that all the keys can be revealed with a time complexity of only O(⌈MNlogc⁡(MN)⌉). Furthermore, some improvement suggestions are proposed.","tags":[],"title":"Cryptanalyzing an image encryption based on a modified Henon map using hybrid chaotic shift transform","type":"publications"}]